{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600851c4-934f-42aa-a78e-1044d84d75d7",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc039a2-89a9-43c9-9034-a2366eb69e20",
   "metadata": {},
   "source": [
    "ans - Bayes' theorem is a fundamental concept in probability theory and statistics named after the Reverend Thomas Bayes. It describes how to update or revise the probability of an event based on new evidence or information.\n",
    "\n",
    "Mathematically, Bayes' theorem can be stated as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the conditional probability of event B occurring given that event A has occurred.\n",
    "P(A) is the probability of event A occurring (prior probability).\n",
    "P(B) is the probability of event B occurring.\n",
    "In simpler terms, Bayes' theorem allows us to calculate the probability of an event A happening given that we have observed event B. It considers both the prior probability of A and the likelihood of B given A, and then adjusts the probability based on the new evidence.\n",
    "\n",
    "Bayes' theorem has applications in various fields, such as machine learning, data science, medical diagnosis, and spam filtering. It provides a framework for updating beliefs and making informed decisions based on new information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb016c5-b7fe-4e74-b738-1904d4e740cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaddd200-730c-48a1-99fc-12095962b576",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c08cf-b9d9-4fc2-ba06-4def14682802",
   "metadata": {},
   "source": [
    "ans - The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the conditional probability of event B occurring given that event A has occurred.\n",
    "P(A) is the probability of event A occurring (prior probability).\n",
    "P(B) is the probability of event B occurring.\n",
    "This formula allows us to update our belief or estimate of the probability of event A happening, given that we have observed event B. It combines the prior probability of A with the likelihood of B given A, and then normalizes the result by dividing it by the probability of B.\n",
    "\n",
    "By using Bayes' theorem, we can incorporate new evidence or information into our probability calculations and make more accurate predictions or decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf350f-3daa-42d3-b645-2493a55666e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3678d325-5a25-4db7-bdc1-802b1df9093b",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770255c-dd16-4a99-8686-9d5d0a68f1a4",
   "metadata": {},
   "source": [
    "ans - Bayes' theorem is widely used in various practical applications. Here are a few examples of how it is applied in practice:\n",
    "\n",
    "Medical Diagnosis: Bayes' theorem is used in medical diagnosis to update the probability of a disease given certain symptoms or test results. The prior probability represents the prevalence of the disease in the population, and the likelihood of symptoms or test results given the disease helps update the probability of actually having the disease.\n",
    "\n",
    "Spam Filtering: Bayes' theorem is used in spam filtering algorithms to classify emails as spam or non-spam. The algorithm calculates the probability of an email being spam given certain words or characteristics in the email. It combines prior probabilities based on known spam and non-spam emails with the likelihood of observing specific words in spam and non-spam emails.\n",
    "\n",
    "Machine Learning: Bayes' theorem is employed in various machine learning algorithms, particularly in the field of Bayesian statistics. Bayesian machine learning models use prior knowledge or beliefs about the data and update them with observed evidence to make predictions or estimate parameters. Examples include Naive Bayes classifiers and Bayesian regression models.\n",
    "\n",
    "A/B Testing: Bayes' theorem is used in A/B testing, where two versions (A and B) of a website or application are compared to determine which performs better. By applying Bayes' theorem, it is possible to calculate the probability that one version is better than the other based on the observed data.\n",
    "\n",
    "Risk Assessment: Bayes' theorem is applied in risk assessment and decision-making processes. It allows for the incorporation of new evidence or information to update the probability of an event occurring, which aids in making informed decisions about potential risks.\n",
    "\n",
    "Overall, Bayes' theorem provides a framework for updating probabilities based on new information, making it a valuable tool in various fields where uncertainty and data analysis are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194f715-d49e-4f1c-a0d6-4a4c7857d3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459278ed-49c5-41d2-a972-7631af9b4cd3",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cfe56-73f0-4d5c-9cf4-35db29daa5bf",
   "metadata": {},
   "source": [
    "ans -\n",
    "Bayes' theorem and conditional probability are closely related concepts. Bayes' theorem is actually derived from conditional probability.\n",
    "\n",
    "Conditional probability refers to the probability of an event occurring given that another event has already occurred. It is denoted as P(A|B), where A and B are two events. The notation P(A|B) represents the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "Bayes' theorem provides a way to calculate conditional probabilities by incorporating prior probabilities and likelihoods. It is expressed as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "In this formula, P(A) represents the prior probability of event A occurring, P(B|A) represents the conditional probability of event B occurring given that event A has occurred, P(B) represents the probability of event B occurring, and P(A|B) represents the conditional probability of event A occurring given that event B has occurred.\n",
    "\n",
    "So, Bayes' theorem relates the conditional probability P(A|B) to the prior probability P(A), the conditional probability P(B|A), and the probability of event B, P(B). It allows us to update our beliefs or estimates of the conditional probability based on new evidence or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f85804-e18b-4980-86e8-2f8c00d2b8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633963d3-95f4-453e-8bae-8e0fac15388a",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407fae6-7ba4-4b8d-8279-cee18392a361",
   "metadata": {},
   "source": [
    "ans - When choosing a type of Naive Bayes classifier for a given problem, you need to consider the characteristics of your data and the assumptions made by each classifier variant. Here are some factors to consider:\n",
    "\n",
    "Gaussian Naive Bayes: This classifier assumes that the features follow a Gaussian (normal) distribution. It is suitable for continuous or numeric features that are normally distributed. If your data features exhibit a bell-shaped distribution, Gaussian Naive Bayes can be a good choice.\n",
    "\n",
    "Multinomial Naive Bayes: This classifier assumes that the features are discrete and follow a multinomial distribution. It is commonly used for text classification problems, where features represent word counts or frequencies. If your problem involves categorical or count-based features, Multinomial Naive Bayes is appropriate.\n",
    "\n",
    "Bernoulli Naive Bayes: This classifier assumes binary features (0s and 1s), such as presence or absence of specific attributes. It is commonly used in document classification or sentiment analysis tasks. If your data is binary or features can be represented as binary indicators, Bernoulli Naive Bayes is a suitable choice.\n",
    "\n",
    "The selection of the appropriate Naive Bayes variant depends on the nature and distribution of your data. However, it is important to note that the \"naive\" assumption of independence between features can influence performance. For instance, if there are strong dependencies between features, the Naive Bayes assumption may not hold, and other classifiers like decision trees or logistic regression might be more appropriate.\n",
    "\n",
    "To choose the best variant, it is recommended to perform exploratory data analysis, assess the distribution of features, and consider the specific requirements and assumptions of your problem domain. Additionally, cross-validation and performance evaluation can help determine which Naive Bayes classifier variant performs better on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f42cbd-9d60-4aad-bbed-943873033e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e73034-e078-4517-8986-317a416619cb",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "A 3 3 4 4 3 3 3\n",
    "\n",
    "B 2 2 1 2 2 2 3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c4450-97b3-4f70-b07b-3042b9e591e4",
   "metadata": {},
   "source": [
    "ans = To predict the class for the new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we need to calculate the posterior probabilities for each class and choose the class with the highest probability.\n",
    "\n",
    "Given the frequency table of feature values for each class, we can calculate the conditional probabilities for each feature value given the class. Since the prior probabilities for each class are assumed to be equal, they do not affect the comparison between the classes.\n",
    "\n",
    "First, let's calculate the conditional probabilities for each feature value given each class:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b7666-2017-4cff-87e8-f27160a00f1a",
   "metadata": {},
   "source": [
    "\n",
    "P(X1=3|A) = 4/13\n",
    "P(X1=3|B) = 1/9\n",
    "\n",
    "P(X2=4|A) = 3/13\n",
    "P(X2=4|B) = 3/9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d65f96-58e1-4ebf-9d76-fe6744b2d907",
   "metadata": {},
   "source": [
    "Next, we can calculate the conditional probability for each class given the feature values using Bayes' theorem:\n",
    "\n",
    "P(A|X1=3, X2=4) ∝ P(X1=3|A) * P(X2=4|A)\n",
    "P(A|X1=3, X2=4) = (4/13) * (3/13) = 12/169\n",
    "\n",
    "P(B|X1=3, X2=4) ∝ P(X1=3|B) * P(X2=4|B)\n",
    "P(B|X1=3, X2=4) = (1/9) * (3/9) = 3/81\n",
    "\n",
    "To normalize the probabilities, we divide each probability by the sum of the probabilities:\n",
    "\n",
    "P(A|X1=3, X2=4) = (12/169) / [(12/169) + (3/81)] ≈ 0.848\n",
    "P(B|X1=3, X2=4) = (3/81) / [(12/169) + (3/81)] ≈ 0.152\n",
    "\n",
    "Based on these calculations, the Naive Bayes classifier would predict that the new instance belongs to Class A, as it has a higher posterior probability (0.848) compared to Class B (0.152)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1780d8-b425-492e-af8c-27e74c5c7773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
